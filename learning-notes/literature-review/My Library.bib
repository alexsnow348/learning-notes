@article{beckBreakingDigitalMonopoly2023,
  title = {Breaking {{Up}} a {{Digital Monopoly}}},
  author = {Beck, Micah D. and Moore, Terry R.},
  date = {2023-06},
  journaltitle = {Communications of the ACM},
  shortjournal = {Commun. ACM},
  volume = {66},
  number = {6},
  pages = {38--41},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/3564239},
  url = {https://dl.acm.org/doi/10.1145/3564239},
  urldate = {2023-09-06},
  abstract = {How to decompose a vertically integrated digital monopoly to enable competitive services based on a shared data structure.},
  langid = {english},
  file = {/Users/alexsnow/Documents/Obsidian Vault/learning-notes/literature-review/pdf-documents/beckBreakingDigitalMonopoly2023.pdf}
}

@inproceedings{boiarovLargeScaleLandmark2019,
  title = {Large {{Scale Landmark Recognition}} via {{Deep Metric Learning}}},
  booktitle = {Proceedings of the 28th {{ACM International Conference}} on {{Information}} and {{Knowledge Management}}},
  author = {Boiarov, Andrei and Tyantov, Eduard},
  date = {2019-11-03},
  pages = {169--178},
  publisher = {{ACM}},
  location = {{Beijing China}},
  doi = {10.1145/3357384.3357956},
  url = {https://dl.acm.org/doi/10.1145/3357384.3357956},
  urldate = {2023-12-21},
  abstract = {This paper presents a novel approach for landmark recognition in images that we’ve successfully deployed at Mail.ru. This method enables us to recognize famous places, buildings, monuments, and other landmarks in user photos. The main challenge lies in the fact that it’s very complicated to give a precise definition of what is and what is not a landmark. Some buildings, statues and natural objects are landmarks; others are not. There’s also no database with a fairly large number of landmarks to train a recognition model. A key feature of using landmark recognition in a production environment is that the number of photos containing landmarks is extremely small. This is why the model should have a very low false positive rate as well as high recognition accuracy.},
  eventtitle = {{{CIKM}} '19: {{The}} 28th {{ACM International Conference}} on {{Information}} and {{Knowledge Management}}},
  isbn = {978-1-4503-6976-3},
  langid = {english},
  file = {/Users/alexsnow/Zotero/storage/YS7ML49E/Boiarov and Tyantov - 2019 - Large Scale Landmark Recognition via Deep Metric L.pdf}
}

@book{boydConvexOptimization2004,
  title = {Convex Optimization},
  author = {Boyd, Stephen P. and Vandenberghe, Lieven},
  date = {2004},
  publisher = {{Cambridge University Press}},
  location = {{Cambridge, UK ; New York}},
  isbn = {978-0-521-83378-3},
  langid = {english},
  pagetotal = {716},
  keywords = {Convex functions,Mathematical optimization},
  file = {/Users/alexsnow/Zotero/storage/ZM7SLTPW/Boyd and Vandenberghe - 2004 - Convex optimization.pdf}
}

@article{caoEnhancingRemoteSensing2020,
  title = {Enhancing Remote Sensing Image Retrieval Using a Triplet Deep Metric Learning Network},
  author = {Cao, Rui and Zhang, Qian and Zhu, Jiasong and Li, Qing and Li, Qingquan and Liu, Bozhi and Qiu, Guoping},
  date = {2020-01-17},
  journaltitle = {International Journal of Remote Sensing},
  shortjournal = {International Journal of Remote Sensing},
  volume = {41},
  number = {2},
  pages = {740--751},
  issn = {0143-1161, 1366-5901},
  doi = {10.1080/2150704X.2019.1647368},
  url = {https://www.tandfonline.com/doi/full/10.1080/2150704X.2019.1647368},
  urldate = {2023-12-21},
  abstract = {With the rapid growing of remotely sensed imagery data, there is a high demand for effective and efficient image retrieval tools to manage and exploit such data. In this letter, we present a novel content-based remote sensing image retrieval (RSIR) method based on Triplet deep metric learning convolutional neural network (CNN). By constructing a Triplet network with metric learning objective function, we extract the representative features of the images in a semantic space in which images from the same class are close to each other while those from different classes are far apart. In such a semantic space, simple metric measures such as Euclidean distance can be used directly to compare the similarity of images and effectively retrieve images of the same class. We also investigate a supervised and an unsupervised learning methods for reducing the dimensionality of the learned semantic features. We present comprehensive experimental results on two public RSIR datasets and show that our method significantly outperforms state-of-the-art.},
  langid = {english},
  file = {/Users/alexsnow/Zotero/storage/P2YYH2TU/Cao et al. - 2020 - Enhancing remote sensing image retrieval using a t.pdf}
}

@online{debrabandereSemanticInstanceSegmentation2017,
  title = {Semantic {{Instance Segmentation}} with a {{Discriminative Loss Function}}},
  author = {De Brabandere, Bert and Neven, Davy and Van Gool, Luc},
  date = {2017-08-08},
  eprint = {1708.02551},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1708.02551},
  urldate = {2023-12-21},
  abstract = {Semantic instance segmentation remains a challenging task. In this work we propose to tackle the problem with a discriminative loss function, operating at the pixel level, that encourages a convolutional network to produce a representation of the image that can easily be clustered into instances with a simple post-processing step. The loss function encourages the network to map each pixel to a point in feature space so that pixels belonging to the same instance lie close together while different instances are separated by a wide margin. Our approach of combining an offthe-shelf network with a principled loss function inspired by a metric learning objective is conceptually simple and distinct from recent efforts in instance segmentation. In contrast to previous works, our method does not rely on object proposals or recurrent mechanisms. A key contribution of our work is to demonstrate that such a simple setup without bells and whistles is effective and can perform onpar with more complex methods. Moreover, we show that it does not suffer from some of the limitations of the popular detect-and-segment approaches. We achieve competitive performance on the Cityscapes and CVPPP leaf segmentation benchmarks.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Robotics},
  file = {/Users/alexsnow/Zotero/storage/KB962GMK/De Brabandere et al. - 2017 - Semantic Instance Segmentation with a Discriminati.pdf}
}

@article{dengArcFaceAdditiveAngular,
  title = {{{ArcFace}}: {{Additive Angular Margin Loss}} for {{Deep Face Recognition}}},
  author = {Deng, Jiankang and Guo, Jia and Xue, Niannan and Zafeiriou, Stefanos},
  langid = {english},
  file = {/Users/alexsnow/Zotero/storage/CH2P2ZW2/Deng et al. - ArcFace Additive Angular Margin Loss for Deep Fac.pdf}
}

@article{doctorowCompetitiveCompatibilityLet2021,
  title = {Competitive Compatibility: Let's Fix the Internet, Not the Tech Giants},
  shorttitle = {Competitive Compatibility},
  author = {Doctorow, Cory},
  date = {2021-10},
  journaltitle = {Communications of the ACM},
  shortjournal = {Commun. ACM},
  volume = {64},
  number = {10},
  pages = {26--29},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/3446789},
  url = {https://dl.acm.org/doi/10.1145/3446789},
  urldate = {2023-09-06},
  abstract = {Seeking to make Big Tech less central to the Internet.},
  langid = {english},
  file = {/Users/alexsnow/Documents/Obsidian Vault/learning-notes/literature-review/pdf-documents/doctorowCompetitiveCompatibilityLet2021.pdf;/Users/alexsnow/Documents/Obsidian Vault/learning-notes/literature-review/pdf-documents/doctorowCompetitiveCompatibilityLet22.pdf}
}

@book{ducciNaturalMonopoliesDigital2020,
  title = {Natural {{Monopolies}} in {{Digital Platform Markets}}},
  author = {Ducci, Francesco},
  date = {2020-07-31},
  edition = {1},
  publisher = {{Cambridge University Press}},
  doi = {10.1017/9781108867528},
  url = {https://www.cambridge.org/core/product/identifier/9781108867528/type/book},
  urldate = {2023-09-06},
  isbn = {978-1-108-86752-8 978-1-108-49114-3 978-1-108-81162-0},
  langid = {english},
  file = {/Users/alexsnow/Documents/Obsidian Vault/learning-notes/literature-review/pdf-documents/ducciNaturalMonopoliesDigital2020.pdf}
}

@book{hackingTamingChance1990,
  title = {The Taming of Chance},
  author = {Hacking, Ian},
  date = {1990},
  series = {Ideas in Context},
  publisher = {{Cambridge University Press}},
  location = {{Cambridge [England] ; New York}},
  isbn = {978-0-521-38014-0 978-0-521-38884-9},
  langid = {english},
  pagetotal = {264},
  keywords = {Chance,Necessity (Philosophy)},
  file = {/Users/alexsnow/Documents/Obsidian Vault/learning-notes/literature-review/pdf-documents/hackingTamingChance1990.pdf}
}

@inproceedings{hadsellDimensionalityReductionLearning2006,
  title = {Dimensionality {{Reduction}} by {{Learning}} an {{Invariant Mapping}}},
  booktitle = {2006 {{IEEE Computer Society Conference}} on {{Computer Vision}} and {{Pattern Recognition}} - {{Volume}} 2 ({{CVPR}}'06)},
  author = {Hadsell, R. and Chopra, S. and LeCun, Y.},
  date = {2006},
  volume = {2},
  pages = {1735--1742},
  publisher = {{IEEE}},
  location = {{New York, NY, USA}},
  doi = {10.1109/CVPR.2006.100},
  url = {http://ieeexplore.ieee.org/document/1640964/},
  urldate = {2023-12-21},
  abstract = {Dimensionality reduction involves mapping a set of high dimensional input points onto a low dimensional manifold so that “similar” points in input space are mapped to nearby points on the manifold. Most existing techniques for solving the problem suffer from two drawbacks. First, most of them depend on a meaningful and computable distance metric in input space. Second, they do not compute a “function” that can accurately map new input samples whose relationship to the training data is unknown. We present a method - called Dimensionality Reduction by Learning an Invariant Mapping (DrLIM) - for learning a globally coherent non-linear function that maps the data evenly to the output manifold. The learning relies solely on neighborhood relationships and does not require any distance measure in the input space. The method can learn mappings that are invariant to certain transformations of the inputs, as is demonstrated with a number of experiments. Comparisons are made to other techniques, in particular LLE.},
  eventtitle = {2006 {{IEEE Computer Society Conference}} on {{Computer Vision}} and {{Pattern Recognition}} - {{Volume}} 2 ({{CVPR}}'06)},
  isbn = {978-0-7695-2597-6},
  langid = {english},
  file = {/Users/alexsnow/Zotero/storage/NZJTV92P/Hadsell et al. - 2006 - Dimensionality Reduction by Learning an Invariant .pdf}
}

@book{hindmanInternetTrapHow2020,
  title = {The Internet Trap: How the Digital Economy Builds Monopolies and Undermines Democracy},
  shorttitle = {The Internet Trap},
  author = {Hindman, Matthew Scott},
  date = {2020},
  edition = {First paperback printing},
  publisher = {{Princeton University Press}},
  location = {{Princeton Oxford}},
  isbn = {978-0-691-15926-3 978-0-691-21020-9},
  langid = {english},
  pagetotal = {240},
  file = {/Users/alexsnow/Documents/Obsidian Vault/learning-notes/literature-review/pdf-documents/hindmanInternetTrapHow2020.pdf}
}

@online{hofferDeepMetricLearning2018,
  title = {Deep Metric Learning Using {{Triplet}} Network},
  author = {Hoffer, Elad and Ailon, Nir},
  date = {2018-12-04},
  eprint = {1412.6622},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1412.6622},
  urldate = {2023-12-21},
  abstract = {Deep learning has proven itself as a successful set of models for learning useful semantic representations of data. These, however, are mostly implicitly learned as part of a classification task. In this paper we propose the triplet network model, which aims to learn useful representations by distance comparisons. A similar model was defined by Wang et al. (2014), tailor made for learning a ranking for image information retrieval. Here we demonstrate using various datasets that our model learns a better representation than that of its immediate competitor, the Siamese network. We also discuss future possible usage as a framework for unsupervised learning.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/alexsnow/Zotero/storage/5FVLU536/Hoffer and Ailon - 2018 - Deep metric learning using Triplet network.pdf}
}

@article{kimProxyAnchorLoss,
  title = {Proxy {{Anchor Loss}} for {{Deep Metric Learning}}},
  author = {Kim, Sungyeon and Kim, Dongwon and Cho, Minsu and Kwak, Suha},
  abstract = {Existing metric learning losses can be categorized into two classes: pair-based and proxy-based losses. The former class can leverage fine-grained semantic relations between data points, but slows convergence in general due to its high training complexity. In contrast, the latter class enables fast and reliable convergence, but cannot consider the rich datato-data relations. This paper presents a new proxy-based loss that takes advantages of both pair- and proxy-based methods and overcomes their limitations. Thanks to the use of proxies, our loss boosts the speed of convergence and is robust against noisy labels and outliers. At the same time, it allows embedding vectors of data to interact with each other through its gradients to exploit data-to-data relations. Our method is evaluated on four public benchmarks, where a standard network trained with our loss achieves state-ofthe-art performance and most quickly converges.},
  langid = {english},
  file = {/Users/alexsnow/Zotero/storage/L7TMI2NX/Kim et al. - Proxy Anchor Loss for Deep Metric Learning.pdf}
}

@inproceedings{liuSphereFaceDeepHypersphere2017,
  title = {{{SphereFace}}: {{Deep Hypersphere Embedding}} for {{Face Recognition}}},
  shorttitle = {{{SphereFace}}},
  booktitle = {2017 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Liu, Weiyang and Wen, Yandong and Yu, Zhiding and Li, Ming and Raj, Bhiksha and Song, Le},
  date = {2017-07},
  pages = {6738--6746},
  publisher = {{IEEE}},
  location = {{Honolulu, HI}},
  doi = {10.1109/CVPR.2017.713},
  url = {http://ieeexplore.ieee.org/document/8100196/},
  urldate = {2023-12-21},
  abstract = {This paper addresses deep face recognition (FR) problem under open-set protocol, where ideal face features are expected to have smaller maximal intra-class distance than minimal inter-class distance under a suitably chosen metric space. However, few existing algorithms can effectively achieve this criterion. To this end, we propose the angular softmax (A-Softmax) loss that enables convolutional neural networks (CNNs) to learn angularly discriminative features. Geometrically, A-Softmax loss can be viewed as imposing discriminative constraints on a hypersphere manifold, which intrinsically matches the prior that faces also lie on a manifold. Moreover, the size of angular margin can be quantitatively adjusted by a parameter m. We further derive specific m to approximate the ideal feature criterion. Extensive analysis and experiments on Labeled Face in the Wild (LFW), Youtube Faces (YTF) and MegaFace Challenge 1 show the superiority of A-Softmax loss in FR tasks.},
  eventtitle = {2017 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-5386-0457-1},
  langid = {english},
  file = {/Users/alexsnow/Zotero/storage/HKHZ6MA7/Liu et al. - 2017 - SphereFace Deep Hypersphere Embedding for Face Re.pdf}
}

@book{murphyMachineLearningProbabilistic2012,
  title = {Machine Learning: A Probabilistic Perspective},
  shorttitle = {Machine Learning},
  author = {Murphy, Kevin P.},
  date = {2012},
  series = {Adaptive Computation and Machine Learning Series},
  publisher = {{MIT Press}},
  location = {{Cambridge, MA}},
  isbn = {978-0-262-01802-9},
  langid = {english},
  pagetotal = {1067},
  keywords = {Machine learning,Probabilities},
  file = {/Users/alexsnow/Zotero/storage/L55XSPZX/Murphy - 2012 - Machine learning a probabilistic perspective.pdf}
}

@book{murphyProbabilisticMachineLearning2022,
  title = {Probabilistic Machine Learning: An Introduction},
  shorttitle = {Probabilistic Machine Learning},
  author = {Murphy, Kevin P.},
  date = {2022},
  series = {Adaptive Computation and Machine Learning Series},
  publisher = {{The MIT Press}},
  location = {{Cambridge, Massachusetts}},
  abstract = {"This book provides a detailed and up-to-date coverage of machine learning. It is unique in that it unifies approaches based on deep learning with approaches based on probabilistic modeling and inference. It provides mathematical background (e.g. linear algebra, optimization), basic topics (e.g., linear and logistic regression, deep neural networks), as well as more advanced topics (e.g., Gaussian processes). It provides a perfect introduction for people who want to understand cutting edge work in top machine learning conferences such as NeurIPS, ICML and ICLR"--},
  isbn = {978-0-262-04682-4},
  langid = {english},
  pagetotal = {826},
  keywords = {Machine learning,Probabilities},
  file = {/Users/alexsnow/Zotero/storage/U8R4QXJX/Murphy - 2022 - Probabilistic machine learning an introduction.pdf}
}

@online{ranjanL2constrainedSoftmaxLoss2017,
  title = {L2-Constrained {{Softmax Loss}} for {{Discriminative Face Verification}}},
  author = {Ranjan, Rajeev and Castillo, Carlos D. and Chellappa, Rama},
  date = {2017-06-07},
  eprint = {1703.09507},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1703.09507},
  urldate = {2023-12-21},
  abstract = {In recent years, the performance of face verification systems has significantly improved using deep convolutional neural networks (DCNNs). A typical pipeline for face verification includes training a deep network for subject classification with softmax loss, using the penultimate layer output as the feature descriptor, and generating a cosine similarity score given a pair of face images. The softmax loss function does not optimize the features to have higher similarity score for positive pairs and lower similarity score for negative pairs, which leads to a performance gap. In this paper, we add an L2-constraint to the feature descriptors which restricts them to lie on a hypersphere of a fixed radius. This module can be easily implemented using existing deep learning frameworks. We show that integrating this simple step in the training pipeline significantly boosts the performance of face verification. Specifically, we achieve state-of-the-art results on the challenging IJB-A dataset, achieving True Accept Rate of 0.909 at False Accept Rate 0.0001 on the face verification protocol. Additionally, we achieve state-of-the-art performance on LFW dataset with an accuracy of 99.78\%, and competing performance on YTF dataset with accuracy of 96.08\%.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/alexsnow/Zotero/storage/ZPDPBJ38/Ranjan et al. - 2017 - L2-constrained Softmax Loss for Discriminative Fac.pdf}
}

@online{saftescuKidnappedRadarTopological2020,
  title = {Kidnapped {{Radar}}: {{Topological Radar Localisation}} Using {{Rotationally-Invariant Metric Learning}}},
  shorttitle = {Kidnapped {{Radar}}},
  author = {Săftescu, Ştefan and Gadd, Matthew and De Martini, Daniele and Barnes, Dan and Newman, Paul},
  date = {2020-01-26},
  eprint = {2001.09438},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  url = {http://arxiv.org/abs/2001.09438},
  urldate = {2023-12-21},
  abstract = {This paper presents a system for robust, large-scale topological localisation using Frequency-Modulated ContinuousWave (FMCW) scanning radar. We learn a metric space for embedding polar radar scans using CNN and NetVLAD architectures traditionally applied to the visual domain. However, we tailor the feature extraction for more suitability to the polar nature of radar scan formation using cylindrical convolutions, anti-aliasing blurring, and azimuth-wise max-pooling; all in order to bolster the rotational invariance. The enforced metric space is then used to encode a reference trajectory, serving as a map, which is queried for nearest neighbours (NNs) for recognition of places at run-time. We demonstrate the performance of our topological localisation system over the course of many repeat forays using the largest radar-focused mobile autonomy dataset released to date, totalling 280 km of urban driving, a small portion of which we also use to learn the weights of the modified architecture. As this work represents a novel application for FMCW radar, we analyse the utility of the proposed method via a comprehensive set of metrics which provide insight into the efficacy when used in a realistic system, showing improved performance over the root architecture even in the face of random rotational perturbation.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Robotics,Electrical Engineering and Systems Science - Signal Processing},
  file = {/Users/alexsnow/Zotero/storage/S9Q7NLN9/Săftescu et al. - 2020 - Kidnapped Radar Topological Radar Localisation us.pdf}
}

@article{schneiderEuropeanUnionDigital,
  title = {The {{European Union}}’s {{Digital Markets Act Seeks}} to {{Regulate Competition}} with {{Little Regard}} to {{Impact}} on {{Consumers}}},
  author = {Schneider, Henrique},
  langid = {english},
  file = {/Users/alexsnow/Documents/Obsidian Vault/learning-notes/literature-review/pdf-documents/schneiderEuropeanUnionDigital.pdf}
}

@inproceedings{schroffFaceNetUnifiedEmbedding2015,
  title = {{{FaceNet}}: {{A}} Unified Embedding for Face Recognition and Clustering},
  shorttitle = {{{FaceNet}}},
  booktitle = {2015 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Schroff, Florian and Kalenichenko, Dmitry and Philbin, James},
  date = {2015-06},
  pages = {815--823},
  publisher = {{IEEE}},
  location = {{Boston, MA, USA}},
  doi = {10.1109/CVPR.2015.7298682},
  url = {http://ieeexplore.ieee.org/document/7298682/},
  urldate = {2023-12-21},
  abstract = {Despite significant recent advances in the field of face recognition [10, 14, 15, 17], implementing face verification and recognition efficiently at scale presents serious challenges to current approaches. In this paper we present a system, called FaceNet, that directly learns a mapping from face images to a compact Euclidean space where distances directly correspond to a measure of face similarity. Once this space has been produced, tasks such as face recognition, verification and clustering can be easily implemented using standard techniques with FaceNet embeddings as feature vectors.},
  eventtitle = {2015 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-4673-6964-0},
  langid = {english},
  file = {/Users/alexsnow/Zotero/storage/Q3LA5WTC/Schroff et al. - 2015 - FaceNet A unified embedding for face recognition .pdf}
}

@online{sermanetTimeContrastiveNetworksSelfSupervised2018,
  title = {Time-{{Contrastive Networks}}: {{Self-Supervised Learning}} from {{Video}}},
  shorttitle = {Time-{{Contrastive Networks}}},
  author = {Sermanet, Pierre and Lynch, Corey and Chebotar, Yevgen and Hsu, Jasmine and Jang, Eric and Schaal, Stefan and Levine, Sergey},
  date = {2018-03-19},
  eprint = {1704.06888},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1704.06888},
  urldate = {2023-12-21},
  abstract = {We propose a self-supervised approach for learning representations and robotic behaviors entirely from unlabeled videos recorded from multiple viewpoints, and study how this representation can be used in two robotic imitation settings: imitating object interactions from videos of humans, and imitating human poses. Imitation of human behavior requires a viewpoint-invariant representation that captures the relationships between end-effectors (hands or robot grippers) and the environment, object attributes, and body pose. We train our representations using a metric learning loss, where multiple simultaneous viewpoints of the same observation are attracted in the embedding space, while being repelled from temporal neighbors which are often visually similar but functionally different. In other words, the model simultaneously learns to recognize what is common between different-looking images, and what is different between similar-looking images. This signal causes our model to discover attributes that do not change across viewpoint, but do change across time, while ignoring nuisance variables such as occlusions, motion blur, lighting and background. We demonstrate that this representation can be used by a robot to directly mimic human poses without an explicit correspondence, and that it can be used as a reward function within a reinforcement learning algorithm. While representations are learned from an unlabeled collection of task-related videos, robot behaviors such as pouring are learned by watching a single 3rd-person demonstration by a human. Reward functions obtained by following the human demonstrations under the learned representation enable efficient reinforcement learning that is practical for real-world robotic systems. Video results, open-source code and dataset are available at https://sermanet.github.io/imitate},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Robotics},
  file = {/Users/alexsnow/Zotero/storage/ZRMI4VW4/Sermanet et al. - 2018 - Time-Contrastive Networks Self-Supervised Learnin.pdf}
}

@article{sohnImprovedDeepMetric,
  title = {Improved {{Deep Metric Learning}} with {{Multi-class N-pair Loss Objective}}},
  author = {Sohn, Kihyuk},
  abstract = {Deep metric learning has gained much popularity in recent years, following the success of deep learning. However, existing frameworks of deep metric learning based on contrastive loss and triplet loss often suffer from slow convergence, partially because they employ only one negative example while not interacting with the other negative classes in each update. In this paper, we propose to address this problem with a new metric learning objective called multi-class N -pair loss. The proposed objective function firstly generalizes triplet loss by allowing joint comparison among more than one negative examples – more specifically, N -1 negative examples – and secondly reduces the computational burden of evaluating deep embedding vectors via an efficient batch construction strategy using only N pairs of examples, instead of (N +1)×N . We demonstrate the superiority of our proposed loss to the triplet loss as well as other competing loss functions for a variety of tasks on several visual recognition benchmark, including fine-grained object recognition and verification, image clustering and retrieval, and face verification and identification.},
  langid = {english},
  file = {/Users/alexsnow/Zotero/storage/U4XPYY7F/Sohn - Improved Deep Metric Learning with Multi-class N-p.pdf}
}

@article{stuckeHBCDaoaedmtraeIpdAaernaeietAosllMLtehotenaoRFpeeoawlsizoTeneOschuItr,
  title = {{{HBCDaoaedmtraeIpdAaernaeietAosllMLtehotenaoRFpeeoawlsizoTeneOschuItr}}’s a},
  author = {Stucke, Maurice E},
  langid = {english},
  file = {/Users/alexsnow/Documents/Obsidian Vault/learning-notes/literature-review/pdf-documents/stuckeHBCDaoaedmtraeIpdAaernaeietAosllMLtehotenaoRFpeeoawlsizoTeneOschuItr.pdf}
}

@book{suttonReinforcementLearningIntroduction2018,
  title = {Reinforcement Learning: An Introduction},
  shorttitle = {Reinforcement Learning},
  author = {Sutton, Richard S. and Barto, Andrew G.},
  date = {2018},
  series = {Adaptive Computation and Machine Learning Series},
  edition = {Second edition},
  publisher = {{The MIT Press}},
  location = {{Cambridge, Massachusetts}},
  abstract = {"Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives while interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the field's key ideas and algorithms."--},
  isbn = {978-0-262-03924-6},
  langid = {english},
  pagetotal = {526},
  keywords = {Reinforcement learning},
  file = {/Users/alexsnow/Documents/uni-hildesheim/textbooks/RLbook2020.pdf}
}

@article{vardiACMEthicsCorporate2022,
  title = {{{ACM}}, Ethics, and Corporate Behavior},
  author = {Vardi, Moshe Y.},
  date = {2022-03},
  journaltitle = {Communications of the ACM},
  shortjournal = {Commun. ACM},
  volume = {65},
  number = {3},
  pages = {5--5},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/3516423},
  url = {https://dl.acm.org/doi/10.1145/3516423},
  urldate = {2023-09-06},
  langid = {english},
  file = {/Users/alexsnow/Documents/Obsidian Vault/learning-notes/literature-review/pdf-documents/vardiACMEthicsCorporate2022.pdf}
}

@article{wangAdditiveMarginSoftmax2018,
  title = {Additive {{Margin Softmax}} for {{Face Verification}}},
  author = {Wang, Feng and Liu, Weiyang and Liu, Haijun and Cheng, Jian},
  date = {2018-07},
  journaltitle = {IEEE Signal Processing Letters},
  shortjournal = {IEEE Signal Process. Lett.},
  volume = {25},
  number = {7},
  eprint = {1801.05599},
  eprinttype = {arxiv},
  eprintclass = {cs},
  pages = {926--930},
  issn = {1070-9908, 1558-2361},
  doi = {10.1109/LSP.2018.2822810},
  url = {http://arxiv.org/abs/1801.05599},
  urldate = {2023-12-21},
  abstract = {In this paper, we propose a conceptually simple and geometrically interpretable objective function, i.e. additive margin Softmax (AM-Softmax), for deep face verification. In general, the face verification task can be viewed as a metric learning problem, so learning large-margin face features whose intra-class variation is small and inter-class difference is large is of great importance in order to achieve good performance. Recently, Large-margin Softmax [10] and Angular Softmax [9] have been proposed to incorporate the angular margin in a multiplicative manner. In this work, we introduce a novel additive angular margin for the Softmax loss, which is intuitively appealing and more interpretable than the existing works. We also emphasize and discuss the importance of feature normalization in the paper. Most importantly, our experiments on LFW and MegaFace show that our additive margin softmax loss consistently performs better than the current state-of-the-art methods using the same network architecture and training dataset. Our code has also been made available1.},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/alexsnow/Zotero/storage/RKU924GQ/Wang et al. - 2018 - Additive Margin Softmax for Face Verification.pdf}
}

@inproceedings{wangCosFaceLargeMargin2018,
  title = {{{CosFace}}: {{Large Margin Cosine Loss}} for {{Deep Face Recognition}}},
  shorttitle = {{{CosFace}}},
  booktitle = {2018 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Wang, Hao and Wang, Yitong and Zhou, Zheng and Ji, Xing and Gong, Dihong and Zhou, Jingchao and Li, Zhifeng and Liu, Wei},
  date = {2018-06},
  pages = {5265--5274},
  publisher = {{IEEE}},
  location = {{Salt Lake City, UT}},
  doi = {10.1109/CVPR.2018.00552},
  url = {https://ieeexplore.ieee.org/document/8578650/},
  urldate = {2023-12-21},
  abstract = {Face recognition has made extraordinary progress owing to the advancement of deep convolutional neural networks (CNNs). The central task of face recognition, including face verification and identification, involves face feature discrimination. However, the traditional softmax loss of deep CNNs usually lacks the power of discrimination. To address this problem, recently several loss functions such as center loss, large margin softmax loss, and angular softmax loss have been proposed. All these improved losses share the same idea: maximizing inter-class variance and minimizing intra-class variance. In this paper, we propose a novel loss function, namely large margin cosine loss (LMCL), to realize this idea from a different perspective. More specifically, we reformulate the softmax loss as a cosine loss by L2 normalizing both features and weight vectors to remove radial variations, based on which a cosine margin term is introduced to further maximize the decision margin in the angular space. As a result, minimum intra-class variance and maximum inter-class variance are achieved by virtue of normalization and cosine decision margin maximization. We refer to our model trained with LMCL as CosFace. Extensive experimental evaluations are conducted on the most popular public-domain face recognition datasets such as MegaFace Challenge, Youtube Faces (YTF) and Labeled Face in the Wild (LFW). We achieve the state-of-the-art performance on these benchmarks, which confirms the effectiveness of our proposed approach.},
  eventtitle = {2018 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-5386-6420-9},
  langid = {english},
  file = {/Users/alexsnow/Zotero/storage/N8AD9493/Wang et al. - 2018 - CosFace Large Margin Cosine Loss for Deep Face Re.pdf}
}

@incollection{wenDiscriminativeFeatureLearning2016,
  title = {A {{Discriminative Feature Learning Approach}} for {{Deep Face Recognition}}},
  booktitle = {Computer {{Vision}} – {{ECCV}} 2016},
  author = {Wen, Yandong and Zhang, Kaipeng and Li, Zhifeng and Qiao, Yu},
  editor = {Leibe, Bastian and Matas, Jiri and Sebe, Nicu and Welling, Max},
  date = {2016},
  volume = {9911},
  pages = {499--515},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-46478-7_31},
  url = {http://link.springer.com/10.1007/978-3-319-46478-7_31},
  urldate = {2023-12-21},
  abstract = {Convolutional neural networks (CNNs) have been widely used in computer vision community, significantly improving the stateof-the-art. In most of the available CNNs, the softmax loss function is used as the supervision signal to train the deep model. In order to enhance the discriminative power of the deeply learned features, this paper proposes a new supervision signal, called center loss, for face recognition task. Specifically, the center loss simultaneously learns a center for deep features of each class and penalizes the distances between the deep features and their corresponding class centers. More importantly, we prove that the proposed center loss function is trainable and easy to optimize in the CNNs. With the joint supervision of softmax loss and center loss, we can train a robust CNNs to obtain the deep features with the two key learning objectives, inter-class dispension and intra-class compactness as much as possible, which are very essential to face recognition. It is encouraging to see that our CNNs (with such joint supervision) achieve the state-of-the-art accuracy on several important face recognition benchmarks, Labeled Faces in the Wild (LFW), YouTube Faces (YTF), and MegaFace Challenge. Especially, our new approach achieves the best results on MegaFace (the largest public domain face benchmark) under the protocol of small training set (contains under 500000 images and under 20000 persons), significantly improving the previous results and setting new state-of-the-art for both face recognition and face verification tasks.},
  isbn = {978-3-319-46477-0 978-3-319-46478-7},
  langid = {english},
  file = {/Users/alexsnow/Zotero/storage/4J394D7A/Wen et al. - 2016 - A Discriminative Feature Learning Approach for Dee.pdf}
}

@article{xingDistanceMetricLearning,
  title = {Distance {{Metric Learning}} with {{Application}} to {{Clustering}} with {{Side-Information}}},
  author = {Xing, Eric P and Jordan, Michael I and Russell, Stuart J and Ng, Andrew Y},
  abstract = {Many algorithms rely critically on being given a good metric over their inputs. For instance, data can often be clustered in many “plausible” ways, and if a clustering algorithm such as K-means initially fails to find one that is meaningful to a user, the only recourse may be for the user to manually tweak the metric until sufficiently good clusters are found. For these and other applications requiring good metrics, it is desirable that we provide a more systematic way for users to indicate what they consider “similar.” For instance, we may ask them to provide examples. In this paper, we present an algorithm that, given examples of similar (and, if desired, dissimilar) pairs of points in ¢¤£ , learns a distance metric over ¢¥£ that respects these relationships. Our method is based on posing metric learning as a convex optimization problem, which allows us to give efficient, local-optima-free algorithms. We also demonstrate empirically that the learned metrics can be used to significantly improve clustering performance.},
  langid = {english},
  file = {/Users/alexsnow/Zotero/storage/DC3EKMKD/Xing et al. - Distance Metric Learning with Application to Clust.pdf}
}
